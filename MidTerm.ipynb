{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"my code trial.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"46ebf68b"},"source":["# font2img\n","- ttf 파일의 폰트를 가져와 이미지로 바꾸는 작업"],"id":"46ebf68b"},{"cell_type":"code","metadata":{"id":"b7a85cdf","executionInfo":{"status":"ok","timestamp":1636056574907,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["import argparse\n","import sys\n","import glob\n","import numpy as np\n","import io, os\n","from PIL import Image\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","import collections"],"id":"b7a85cdf","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9148e69","executionInfo":{"status":"ok","timestamp":1636056578837,"user_tz":-540,"elapsed":546,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["SRC_PATH = './fonts/source/'\n","TRG_PATH = './fonts/target/'\n","OUTPUT_PATH = './dataset_png/'"],"id":"c9148e69","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"842264c6","executionInfo":{"status":"ok","timestamp":1636056579328,"user_tz":-540,"elapsed":1,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def draw_single_char(ch, font, canvas_size):\n","    image = Image.new('L', (canvas_size, canvas_size), color = 255)\n","    drawing = ImageDraw.Draw(image)\n","    w, h = drawing.textsize(ch, font=font)\n","    drawing.text(\n","        ((canvas_size-w)/2, (canvas_size-h)/2),\n","        ch,\n","        fill=(0),\n","        font=font\n","    )\n","    flag = np.sum(np.array(image))\n","    \n","    #해당 font에 글자가 없으면 return None\n","    if flag == 255 * 128 * 128:\n","        return None\n","    \n","    return image"],"id":"842264c6","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"b41b240a","executionInfo":{"status":"ok","timestamp":1636056579329,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def draw_example(ch, src_font, dst_font, canvas_size):\n","    dst_img = draw_single_char(ch, dst_font, canvas_size)\n","    \n","    #해당 font에 글자가 없으면 return None\n","    if not dst_img:\n","        return None\n","    \n","    src_img = draw_single_char(ch, src_font, canvas_size)\n","    example_img = Image.new(\"RGB\", (canvas_size*2,canvas_size), (255,255,255)).convert('L')\n","    example_img.paste(dst_img, (0,0))\n","    example_img.paste(src_img, (canvas_size,0))\n","    return example_img"],"id":"b41b240a","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c721ca0","executionInfo":{"status":"ok","timestamp":1636056579836,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def draw_handwriting(ch, src_font, canvas_size, dst_folder, label, count):\n","    dst_path = dst_folder + \"%d_%04d\" % (label, count) + \".png\"\n","    dst_img = Image.open(dst_path)\n","    src_img = draw_single_char(ch, src_font, canvas_size)\n","    example_img = Image.new(\"RGB\", (canvas_size * 2, canvas_size), (255, 255, 255)).convert('L')\n","    example_img.paste(dst_img, (0, 0))\n","    example_img.paste(src_img, (canvas_size, 0))\n","    return example_img\n"],"id":"8c721ca0","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0492c961"},"source":["# Package\n","- img to pickle"],"id":"0492c961"},{"cell_type":"code","metadata":{"id":"fff460dd","executionInfo":{"status":"ok","timestamp":1636056579836,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["from __future__ import print_function\n","from __future__ import absolute_import\n","\n","import argparse\n","import glob\n","import os\n","import pickle as pickle\n","import random"],"id":"fff460dd","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aca6332","executionInfo":{"status":"ok","timestamp":1636056579836,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def pickle_examples(from_dir, train_path, val_path, train_val_split=0.2, with_charid=False):\n","    \"\"\"\n","    Compile a list of examples into pickled format, so during\n","    the training, all io will happen in memory\n","    \"\"\"\n","    paths = glob.glob(os.path.join(from_dir, \"*.png\"))\n","    with open(train_path, 'wb') as ft:\n","        with open(val_path, 'wb') as fv:\n","            print('all data num:', len(paths))\n","            c = 1\n","            val_count = 0\n","            train_count = 0\n","            if with_charid:\n","                print('pickle with charid')\n","                for p in paths:\n","                    c += 1\n","                    label = int(os.path.basename(p).split(\"_\")[0])#font\n","                    charid = int(os.path.basename(p).split(\"_\")[1].split(\".\")[0])#가나다\n","                    with open(p, 'rb') as f:\n","                        img_bytes = f.read()\n","                        example = (label, charid, img_bytes)\n","                        r = random.random()\n","                        if r < train_val_split:\n","                            pickle.dump(example, fv)\n","                            val_count += 1\n","                            if val_count % 10000 == 0:\n","                                print(\"%d imgs saved in val.obj\" % val_count)\n","                        else:\n","                            pickle.dump(example, ft)\n","                            train_count += 1\n","                            if train_count % 10000 == 0:\n","                                print(\"%d imgs saved in train.obj\" % train_count)\n","                print(\"%d imgs saved in val.obj, end\" % val_count)\n","                print(\"%d imgs saved in train.obj, end\" % train_count)\n","            else:\n","                for p in paths:\n","                    c += 1\n","                    label = int(os.path.basename(p).split(\"_\")[0])\n","                    with open(p, 'rb') as f:\n","                        img_bytes = f.read()\n","                        example = (label, img_bytes)\n","                        r = random.random()\n","                        if r < train_val_split:\n","                            pickle.dump(example, fv)\n","                            val_count += 1\n","                            if val_count % 10000 == 0:\n","                                print(\"%d imgs saved in val.obj\" % val_count)\n","                        else:\n","                            pickle.dump(example, ft)\n","                            train_count += 1\n","                            if train_count % 10000 == 0:\n","                                print(\"%d imgs saved in train.obj\" % train_count)\n","                print(\"%d imgs saved in val.obj, end\" % val_count)\n","                print(\"%d imgs saved in train.obj, end\" % train_count)\n","            return"],"id":"4aca6332","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"75202c8d","executionInfo":{"status":"ok","timestamp":1636056579837,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def pickle_interpolation_data(from_dir, save_path, char_ids, font_filter):\n","    paths = glob.glob(os.path.join(from_dir, \"*.png\"))\n","    with open(save_path, 'wb') as ft:\n","        c = 0\n","        for p in paths:\n","            charid = int(p.split('/')[-1].split('.')[0].split('_')[1])\n","            label = int(os.path.basename(p).split(\"_\")[0])\n","            if (charid in char_ids) and (label in font_filter):\n","                c += 1\n","                with open(p, 'rb') as f:\n","                    img_bytes = f.read()\n","                    example = (label, charid, img_bytes)\n","                    pickle.dump(example, ft)\n","        print('data num:', c)\n","        return"],"id":"75202c8d","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83b4de75"},"source":["# Function\n","- deep learning functions : conv2d, relu etc."],"id":"83b4de75"},{"cell_type":"code","metadata":{"id":"675477e1","executionInfo":{"status":"ok","timestamp":1636056604814,"user_tz":-540,"elapsed":24980,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["from __future__ import print_function\n","from __future__ import absolute_import\n","import numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, TensorDataset"],"id":"675477e1","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"aded2cf9","executionInfo":{"status":"ok","timestamp":1636056604815,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def batch_norm(c_out, momentum=0.1):\n","    return nn.BatchNorm2d(c_out, momentum=momentum)"],"id":"aded2cf9","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0e17a4f","executionInfo":{"status":"ok","timestamp":1636056604815,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def conv2d(c_in, c_out, k_size, stride=2, pad=1, dilation=1, bn=True, lrelu=True, leak=0.2):\n","    layers =[]\n","    if lrelu:\n","        layers.append(nn.LeakyReLU(leak))\n","    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad))\n","    if bn:\n","        layers.append(nn.BatchNorm2d(c_out))\n","    return nn.Sequential(*layers)"],"id":"a0e17a4f","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbf5bb1b","executionInfo":{"status":"ok","timestamp":1636056604815,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def deconv2d(c_in, c_out, k_size=3, stride=1, pad=1, dilation=1, bn=True, dropout=False, p=0.5):\n","    layers = []\n","    layers.append(nn.LeakyReLU(0.2))\n","    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad))\n","    if bn:\n","        layers.append(nn.BatchNorm2d(c_out))\n","    if dropout:\n","        layers.append(nn.Dropout(p))\n","    return nn.Sequential(*layers)"],"id":"bbf5bb1b","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"6670f9e8","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":395,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def lrelu(leak=0.2):\n","    return nn.LeakyReLU(leak)"],"id":"6670f9e8","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"258eb340","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def dropout(p=0.2):\n","    return nn.Dropout(p)"],"id":"258eb340","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6cdcd77","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def fc(input_size, output_size):\n","    return nn.Linear(input_size, output_size)"],"id":"e6cdcd77","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"c04a4d5b","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def init_embedding(embedding_num, embedding_dim, stddev=0.01):\n","    embedding = torch.randn(embedding_num, embedding_dim) * stddev\n","    embedding = embedding.reshape((embedding_num, 1, 1, embedding_dim))\n","    return embedding"],"id":"c04a4d5b","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f296e9b","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def embedding_lookup(embeddings, embedding_ids, GPU=False):\n","    batch_size = len(embedding_ids)\n","    embedding_dim = embeddings.shape[3]\n","    local_embeddings = []\n","    for id_ in embedding_ids:\n","        if GPU:\n","            local_embeddings.append(embeddings[id_].cpu().numpy())\n","        else:\n","            local_embeddings.append(embeddings[id_].data.numpy())\n","    local_embeddings = torch.from_numpy(np.array(local_embeddings))\n","    if GPU:\n","        local_embeddings = local_embeddings.cuda()\n","    local_embeddings = local_embeddings.reshape(batch_size, embedding_dim, 1, 1)\n","    return local_embeddings"],"id":"2f296e9b","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0d0febb","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def interpolated_embedding_lookup(embeddings, interpolated_embedding_ids, grid):\n","    batch_size = len(interpolated_embedding_ids)\n","    interpolated_embeddings = []\n","    embedding_dim = embeddings.shape[3]\n","\n","    for id_ in interpolated_embedding_ids:\n","        interpolated_embeddings.append((embeddings[id_[0]] * (1 - grid) + embeddings[id_[1]] * grid).cpu().numpy())\n","    interpolated_embeddings = torch.from_numpy(np.array(interpolated_embeddings)).cuda()\n","    interpolated_embeddings = interpolated_embeddings.reshape(batch_size, embedding_dim, 1, 1)\n","    return interpolated_embeddings"],"id":"b0d0febb","execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95ee9c19"},"source":["# Utils\n","\n","- data pre-processing etc."],"id":"95ee9c19"},{"cell_type":"code","metadata":{"id":"3949a58c","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["from __future__ import print_function\n","from __future__ import absolute_import\n","\n","import os\n","import glob\n","\n","import imageio\n","import scipy.misc as misc\n","import numpy as np\n","from io import BytesIO\n","from PIL import Image\n","#from scipy.misc import imresize\n","import matplotlib.pyplot as plt"],"id":"3949a58c","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"530dd409","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def pad_seq(seq, batch_size):\n","    # pad the sequence to be the multiples of batch_size\n","    seq_len = len(seq)\n","    if seq_len % batch_size == 0:\n","        return seq\n","    padded = batch_size - (seq_len % batch_size)\n","    seq.extend(seq[:padded])\n","    return seq"],"id":"530dd409","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d5b1e61","executionInfo":{"status":"ok","timestamp":1636056605207,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def bytes_to_file(bytes_img):\n","    return BytesIO(bytes_img)"],"id":"9d5b1e61","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"07fa5c68","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def normalize_image(img):\n","    \"\"\"\n","    Make image zero centered and in between (-1, 1)\n","    \"\"\"\n","    normalized = (img / 127.5) - 1.\n","    return normalized"],"id":"07fa5c68","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"b88e20d3","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def denorm_image(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)"],"id":"b88e20d3","execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dbf4bc3","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def read_split_image(img):\n","    mat = misc.imread(img).astype(np.float)\n","    side = int(mat.shape[1] / 2)\n","    assert side * 2 == mat.shape[1]\n","    img_A = mat[:, :side]  # target\n","    img_B = mat[:, side:]  # source\n","\n","    return img_A, img_B"],"id":"7dbf4bc3","execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"23cb1106","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def shift_and_resize_image(img, shift_x, shift_y, nw, nh):\n","    w, h = img.shape\n","    #enlarged = misc.imresize(img, [nw, nh])\n","    enlarged = Image.fromarray(img).resize(size=(nh, nw))\n","    return enlarged[shift_x:shift_x + w, shift_y:shift_y + h]"],"id":"23cb1106","execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"2c0adcce","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def scale_back(images):\n","    return (images + 1.) / 2."],"id":"2c0adcce","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ea04d33","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def merge(images, size):\n","    h, w = images.shape[1], images.shape[2]\n","    img = np.zeros((h * size[0], w * size[1], 3))\n","    for idx, image in enumerate(images):\n","        i = idx % size[1]\n","        j = idx // size[1]\n","        img[j * h:j * h + h, i * w:i * w + w, :] = image\n","\n","    return img"],"id":"7ea04d33","execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"b520a82c","executionInfo":{"status":"ok","timestamp":1636056605208,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def save_concat_images(imgs, img_path):\n","    concated = np.concatenate(imgs, axis=1)\n","    misc.imsave(img_path, concated)"],"id":"b520a82c","execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cbd20ad","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":380,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def save_gif(gif_path, image_path, file_name):\n","    filenames = sorted(glob.glob(os.path.join(image_path, \"*.png\")))\n","    images = []\n","    for filename in filenames:\n","        images.append(imageio.imread(filename))\n","    imageio.mimsave(os.path.join(gif_path, file_name), images)"],"id":"6cbd20ad","execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"28ca0c33","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def show_comparison(font_num, real_targets, fake_targets, show_num=8):\n","    plt.figure(figsize=(14, show_num//2+1))\n","    for idx in range(show_num):\n","        plt.subplot(show_num//4, 8, 2*idx+1)\n","        plt.imshow(real_targets[font_num][idx].reshape(128, 128), cmap='gray')\n","        plt.title(\"Real [%d]\" % font_num)\n","        plt.axis('off')\n","\n","        plt.subplot(show_num//4, 8, 2*idx+2)\n","        plt.imshow(fake_targets[font_num][idx].reshape(128, 128), cmap='gray')\n","        plt.title(\"Fake [%d]\" % font_num)\n","        plt.axis('off')\n","    plt.show()"],"id":"28ca0c33","execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7601acb","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def tight_crop_image(img, verbose=False, resize_fix=False):\n","    img_size = img.shape[0]\n","    full_white = img_size\n","    col_sum = np.where(full_white - np.sum(img, axis=0) > 1)\n","    row_sum = np.where(full_white - np.sum(img, axis=1) > 1)\n","    y1, y2 = row_sum[0][0], row_sum[0][-1]\n","    x1, x2 = col_sum[0][0], col_sum[0][-1]\n","    cropped_image = img[y1:y2, x1:x2]\n","    cropped_image_size = cropped_image.shape\n","    \n","    if verbose:\n","        print('(left x1, top y1):', (x1, y1))\n","        print('(right x2, bottom y2):', (x2, y2))\n","        print('cropped_image size:', cropped_image_size)\n","        \n","    if type(resize_fix) == int:\n","        origin_h, origin_w = cropped_image.shape\n","        if origin_h > origin_w:\n","            resize_w = int(origin_w * (resize_fix / origin_h))\n","            resize_h = resize_fix\n","        else:\n","            resize_h = int(origin_h * (resize_fix / origin_w))\n","            resize_w = resize_fix\n","        \n","        # resize\n","        cropped_image = Image.fromarray(cropped_image).resize(size=(resize_h, resize_w))\n","        cropped_image = normalize_image(cropped_image)\n","        cropped_image_size = cropped_image.shape\n","        if verbose:\n","            print('resized_image size:', cropped_image_size)\n","        \n","    elif type(resize_fix) == float:\n","        origin_h, origin_w = cropped_image.shape\n","        resize_h, resize_w = int(origin_h * resize_fix), int(origin_w * resize_fix)\n","        if resize_h > 120:\n","            resize_h = 120\n","            resize_w = int(resize_w * 120 / resize_h)\n","        if resize_w > 120:\n","            resize_w = 120\n","            resize_h = int(resize_h * 120 / resize_w)\n","        \n","        # resize\n","        cropped_image = Image.fromarray(cropped_image).resize(size=(resize_h, resize_w))\n","        cropped_image = normalize_image(cropped_image)\n","        cropped_image_size = cropped_image.shape\n","        if verbose:\n","            print('resized_image size:', cropped_image_size)\n","    \n","    return cropped_image"],"id":"a7601acb","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"999421f4","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def add_padding(img, image_size=128, verbose=False, pad_value=None):\n","    height, width = img.shape\n","    if not pad_value:\n","        pad_value = img[0][0]\n","    if verbose:\n","        print('original cropped image size:', img.shape)\n","    \n","    # Adding padding of x axis - left, right\n","    pad_x_width = (image_size - width) // 2\n","    pad_x = np.full((height, pad_x_width), pad_value, dtype=np.float32)\n","    img = np.concatenate((pad_x, img), axis=1)\n","    img = np.concatenate((img, pad_x), axis=1)\n","    \n","    width = img.shape[1]\n","\n","    # Adding padding of y axis - top, bottom\n","    pad_y_height = (image_size - height) // 2\n","    pad_y = np.full((pad_y_height, width), pad_value, dtype=np.float32)\n","    img = np.concatenate((pad_y, img), axis=0)\n","    img = np.concatenate((img, pad_y), axis=0)\n","    \n","    # Match to original image size\n","    width = img.shape[1]\n","    if img.shape[0] % 2:\n","        pad = np.full((1, width), pad_value, dtype=np.float32)\n","        img = np.concatenate((pad, img), axis=0)\n","    height = img.shape[0]\n","    if img.shape[1] % 2:\n","        pad = np.full((height, 1), pad_value, dtype=np.float32)\n","        img = np.concatenate((pad, img), axis=1)\n","\n","    if verbose:\n","        print('final image size:', img.shape)\n","    \n","    return img"],"id":"999421f4","execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa578a49","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def centering_image(img, image_size=128, verbose=False, resize_fix=False, pad_value=None):\n","    if not pad_value:\n","        pad_value = img[0][0]\n","    cropped_image = tight_crop_image(img, verbose=verbose, resize_fix=resize_fix)\n","    centered_image = add_padding(cropped_image, image_size=image_size, verbose=verbose, pad_value=pad_value)\n","    \n","    return centered_image"],"id":"aa578a49","execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3dd935d","executionInfo":{"status":"ok","timestamp":1636056605584,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def chars_to_ids(sentence):\n","    charset = []\n","    for i in range(0xac00,0xd7a4):\n","        charset.append(chr(i))\n","\n","    fixed_char_ids = []\n","    for char in sentence:\n","        fixed_char_ids.append(charset.index(char))\n","        \n","    return fixed_char_ids"],"id":"a3dd935d","execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"6026af96","executionInfo":{"status":"ok","timestamp":1636056605585,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def round_function(i):\n","    if i < -0.95:\n","        return -1\n","    elif i > 0.95:\n","        return 1\n","    else:\n","        return i"],"id":"6026af96","execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03ed4be2"},"source":["# Dataset\n","- load dataset, data pre-processing"],"id":"03ed4be2"},{"cell_type":"code","metadata":{"id":"8c442259","executionInfo":{"status":"ok","timestamp":1636056605585,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["from __future__ import print_function\n","from __future__ import absolute_import\n","import pickle as pickle\n","import numpy as np\n","import random\n","import os\n","import torch"],"id":"8c442259","execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"010094ac","executionInfo":{"status":"ok","timestamp":1636056605585,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def get_batch_iter(examples, batch_size, augment, with_charid=False):\n","    # the transpose ops requires deterministic\n","    # batch size, thus comes the padding\n","    padded = pad_seq(examples, batch_size)\n","\n","    def process(img):\n","        img = bytes_to_file(img)\n","        try:\n","            img_A, img_B = read_split_image(img)\n","            if augment:\n","                # augment the image by:\n","                # 1) enlarge the image\n","                # 2) random crop the image back to its original size\n","                # NOTE: image A and B needs to be in sync as how much\n","                # to be shifted\n","                w, h = img_A.shape\n","                multiplier = random.uniform(1.00, 1.20)\n","                # add an eps to prevent cropping issue\n","                nw = int(multiplier * w) + 1\n","                nh = int(multiplier * h) + 1\n","                shift_x = int(np.ceil(np.random.uniform(0.01, nw - w)))\n","                shift_y = int(np.ceil(np.random.uniform(0.01, nh - h)))\n","                img_A = shift_and_resize_image(img_A, shift_x, shift_y, nw, nh)\n","                img_B = shift_and_resize_image(img_B, shift_x, shift_y, nw, nh)\n","            img_A = normalize_image(img_A)\n","            img_A = img_A.reshape(1, len(img_A), len(img_A[0]))\n","            img_B = normalize_image(img_B)\n","            img_B = img_B.reshape(1, len(img_B), len(img_B[0]))\n","            return np.concatenate([img_A, img_B], axis=0)\n","        finally:\n","            img.close()\n","            \n","    def batch_iter(with_charid=with_charid):\n","        for i in range(0, len(padded), batch_size):\n","            batch = padded[i: i + batch_size]\n","            labels = [e[0] for e in batch]\n","            if with_charid:\n","                charid = [e[1] for e in batch]\n","                image = [process(e[2]) for e in batch]\n","                image = np.array(image).astype(np.float32)\n","                image = torch.from_numpy(image)\n","                # stack into tensor\n","                yield [labels, charid, image]\n","            else:\n","                image = [process(e[1]) for e in batch]\n","                image = np.array(image).astype(np.float32)\n","                image = torch.from_numpy(image)\n","                # stack into tensor\n","                yield [labels, image]\n","\n","    return batch_iter(with_charid=with_charid)"],"id":"010094ac","execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"3d468d10","executionInfo":{"status":"ok","timestamp":1636056605585,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["#check _EOFERROR\n","\n","class PickledImageProvider(object):\n","    def __init__(self, obj_path, verbose):\n","        self.obj_path = obj_path\n","        self.verbose = verbose\n","        self.examples = self.load_pickled_examples()\n","\n","    def load_pickled_examples(self):\n","        with open(self.obj_path, \"rb\") as of:\n","            examples = list()\n","            while True:\n","                try:\n","                    e = pickle.load(of)\n","                    examples.append(e)\n","                except EOFError:\n","                    break\n","                except Exception:\n","                    pass\n","            if self.verbose:\n","                print(\"unpickled total %d examples\" % len(examples))\n","            return examples"],"id":"3d468d10","execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1276fbd","executionInfo":{"status":"ok","timestamp":1636056605585,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["class TrainDataProvider(object):\n","    def __init__(self, data_dir, train_name=\"train.obj\", val_name=\"val.obj\", \\\n","                 filter_by_font=None, filter_by_charid=None, verbose=True, val=True):\n","        self.data_dir = data_dir\n","        self.filter_by_font = filter_by_font\n","        self.filter_by_charid = filter_by_charid\n","        self.train_path = os.path.join(self.data_dir, train_name)\n","        self.val_path = os.path.join(self.data_dir, val_name)\n","        self.train = PickledImageProvider(self.train_path, verbose)\n","        if val:\n","            self.val = PickledImageProvider(self.val_path, verbose)\n","        if self.filter_by_font:\n","            if verbose:\n","                print(\"filter by label ->\", filter_by_font)\n","            self.train.examples = [e for e in self.train.examples if e[0] in self.filter_by_font]\n","            if val:\n","                self.val.examples = [e for e in self.val.examples if e[0] in self.filter_by_font]\n","        if self.filter_by_charid:\n","            if verbose:\n","                print(\"filter by char ->\", filter_by_charid)\n","            self.train.examples = [e for e in self.train.examples if e[1] in filter_by_charid]\n","            if val:\n","                self.val.examples = [e for e in self.val.examples if e[1] in filter_by_charid]\n","        if verbose:\n","            if val:\n","                print(\"train examples -> %d, val examples -> %d\" % (len(self.train.examples), len(self.val.examples)))\n","            else:\n","                print(\"train examples -> %d\" % (len(self.train.examples)))\n","\n","                \n","    def get_train_iter(self, batch_size, shuffle=True, with_charid=False):\n","        training_examples = self.train.examples[:]\n","        if shuffle:\n","            np.random.shuffle(training_examples)\n","           \n","        if with_charid:\n","            return get_batch_iter(training_examples, batch_size, augment=True, with_charid=True)\n","        else:\n","            return get_batch_iter(training_examples, batch_size, augment=True)\n","\n","        \n","    def get_val_iter(self, batch_size, shuffle=True, with_charid=False):\n","        \"\"\"\n","        Validation iterator runs forever\n","        \"\"\"\n","        val_examples = self.val.examples[:]\n","        if shuffle:\n","            np.random.shuffle(val_examples)\n","        if with_charid:\n","            return get_batch_iter(val_examples, batch_size, augment=True, with_charid=True)\n","        else:\n","            return get_batch_iter(val_examples, batch_size, augment=True)\n","\n","        \n","    def compute_total_batch_num(self, batch_size):\n","        \"\"\"Total padded batch num\"\"\"\n","        return int(np.ceil(len(self.train.examples) / float(batch_size)))\n","\n","    \n","    def get_all_labels(self):\n","        \"\"\"Get all training labels\"\"\"\n","        return list({e[0] for e in self.train.examples})\n","\n","    \n","    def get_train_val_path(self):\n","        return self.train_path, self.val_path\n","\n"],"id":"f1276fbd","execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"100ab23c","executionInfo":{"status":"ok","timestamp":1636056606017,"user_tz":-540,"elapsed":435,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def save_fixed_sample(sample_size, img_size, data_dir, save_dir, \\\n","                      val=False, verbose=True, with_charid=True, resize_fix=90):\n","    data_provider = TrainDataProvider(data_dir, verbose=verbose, val=val)\n","    if not val:\n","        train_batch_iter = data_provider.get_train_iter(sample_size, with_charid=with_charid)\n","    else:\n","        train_batch_iter = data_provider.get_val_iter(sample_size, with_charid=with_charid)\n","        \n","    for batch in train_batch_iter:\n","        if with_charid:\n","            font_ids, _, batch_images = batch\n","        else:\n","            font_ids, batch_images = batch\n","        fixed_batch = batch_images.cuda()\n","        fixed_source = fixed_batch[:, 1, :, :].reshape(sample_size, 1, img_size, img_size)\n","        fixed_target = fixed_batch[:, 0, :, :].reshape(sample_size, 1, img_size, img_size)\n","\n","        # centering\n","        for idx, (image_S, image_T) in enumerate(zip(fixed_source, fixed_target)):\n","            image_S = image_S.cpu().detach().numpy().reshape(img_size, img_size)\n","            image_S = np.array(list(map(round_function, image_S.flatten()))).reshape(128, 128)\n","            image_S = centering_image(image_S, resize_fix=90)\n","            fixed_source[idx] = torch.tensor(image_S).view([1, img_size, img_size])\n","            image_T = image_T.cpu().detach().numpy().reshape(img_size, img_size)\n","            image_T = np.array(list(map(round_function, image_T.flatten()))).reshape(128, 128)\n","            image_T = centering_image(image_T, resize_fix=resize_fix)\n","            fixed_target[idx] = torch.tensor(image_T).view([1, img_size, img_size])\n","\n","        fixed_label = np.array(font_ids)\n","        source_with_label = [(label, image_S.cpu().detach().numpy()) \\\n","                             for label, image_S in zip(fixed_label, fixed_source)]\n","        source_with_label = sorted(source_with_label, key=lambda i: i[0])\n","        target_with_label = [(label, image_T.cpu().detach().numpy()) \\\n","                             for label, image_T in zip(fixed_label, fixed_target)]\n","        target_with_label = sorted(target_with_label, key=lambda i: i[0])\n","        fixed_source = torch.tensor(np.array([i[1] for i in source_with_label])).cuda()\n","        fixed_target = torch.tensor(np.array([i[1] for i in target_with_label])).cuda()\n","        fixed_label = sorted(fixed_label)\n","        torch.save(fixed_source, os.path.join(save_dir, 'fixed_source.pkl'))\n","        torch.save(fixed_target, os.path.join(save_dir, 'fixed_target.pkl'))\n","        torch.save(fixed_label, os.path.join(save_dir, 'fixed_label.pkl'))\n","        return"],"id":"100ab23c","execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c782cdd9"},"source":["# Models\n","- Generator(Encoder, Decoder), Discriminator"],"id":"c782cdd9"},{"cell_type":"code","metadata":{"id":"25a699c8","executionInfo":{"status":"ok","timestamp":1636056606017,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["import torch\n","import torch.nn as nn\n","#from function import conv2d, deconv2d, lrelu, fc, embedding_lookup # .function 수정함\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"25a699c8","execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"25cdbebd","executionInfo":{"status":"ok","timestamp":1636056606017,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["def Generator(images, En, De, embeddings, embedding_ids, GPU=False, encode_layers=False):\n","    encoded_source, encode_layers = En(images)\n","    local_embeddings = embedding_lookup(embeddings, embedding_ids, GPU=GPU)\n","    if GPU:\n","        encoded_source = encoded_source.cuda()\n","        local_embeddings = local_embeddings.cuda()\n","    embedded = torch.cat((encoded_source, local_embeddings), 1)\n","    fake_target = De(embedded, encode_layers)\n","    if encode_layers:\n","        return fake_target, encoded_source, encode_layers\n","    else:\n","        return fake_target, encoded_source"],"id":"25cdbebd","execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"39a7e4e1","executionInfo":{"status":"ok","timestamp":1636056606018,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self, img_dim=1, conv_dim=64):\n","        super(Encoder, self).__init__()\n","        self.conv1 = conv2d(img_dim, conv_dim, k_size=5, stride=2, pad=2, dilation=2, lrelu=False, bn=False)\n","        self.conv2 = conv2d(conv_dim, conv_dim*2, k_size=5, stride=2, pad=2, dilation=2)\n","        self.conv3 = conv2d(conv_dim*2, conv_dim*4, k_size=4, stride=2, pad=1, dilation=1)\n","        self.conv4 = conv2d(conv_dim*4, conv_dim*8)\n","        self.conv5 = conv2d(conv_dim*8, conv_dim*8)\n","        self.conv6 = conv2d(conv_dim*8, conv_dim*8)\n","        self.conv7 = conv2d(conv_dim*8, conv_dim*8)\n","        self.conv8 = conv2d(conv_dim*8, conv_dim*8)\n","    \n","    def forward(self, images):\n","        encode_layers = dict()\n","        \n","        e1 = self.conv1(images)\n","        encode_layers['e1'] = e1\n","        e2 = self.conv2(e1)\n","        encode_layers['e2'] = e2\n","        e3 = self.conv3(e2)\n","        encode_layers['e3'] = e3\n","        e4 = self.conv4(e3)\n","        encode_layers['e4'] = e4\n","        e5 = self.conv5(e4)\n","        encode_layers['e5'] = e5\n","        e6 = self.conv6(e5)\n","        encode_layers['e6'] = e6\n","        e7 = self.conv7(e6)\n","        encode_layers['e7'] = e7\n","        encoded_source = self.conv8(e7)\n","        encode_layers['e8'] = encoded_source\n","        \n","        return encoded_source, encode_layers"],"id":"39a7e4e1","execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d615084","executionInfo":{"status":"ok","timestamp":1636056606018,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["class Decoder(nn.Module):\n","    \n","    def __init__(self, img_dim=1, embedded_dim=640, conv_dim=64):\n","        super(Decoder, self).__init__()\n","        self.deconv1 = deconv2d(embedded_dim, conv_dim*8, dropout=True)\n","        self.deconv2 = deconv2d(conv_dim*16, conv_dim*8, dropout=True, k_size=4)\n","        self.deconv3 = deconv2d(conv_dim*16, conv_dim*8, k_size=5, dilation=2, dropout=True)\n","        self.deconv4 = deconv2d(conv_dim*16, conv_dim*8, k_size=4, dilation=2, stride=2)\n","        self.deconv5 = deconv2d(conv_dim*16, conv_dim*4, k_size=4, dilation=2, stride=2)\n","        self.deconv6 = deconv2d(conv_dim*8, conv_dim*2, k_size=4, dilation=2, stride=2)\n","        self.deconv7 = deconv2d(conv_dim*4, conv_dim*1, k_size=4, dilation=2, stride=2)\n","        self.deconv8 = deconv2d(conv_dim*2, img_dim, k_size=4, dilation=2, stride=2, bn=False)\n","    \n","    \n","    def forward(self, embedded, encode_layers):\n","        \n","        d1 = self.deconv1(embedded)\n","        d1 = torch.cat((d1, encode_layers['e7']), dim=1)\n","        d2 = self.deconv2(d1)\n","        d2 = torch.cat((d2, encode_layers['e6']), dim=1)\n","        d3 = self.deconv3(d2)\n","        d3 = torch.cat((d3, encode_layers['e5']), dim=1)\n","        d4 = self.deconv4(d3)\n","        d4 = torch.cat((d4, encode_layers['e4']), dim=1)\n","        d5 = self.deconv5(d4)\n","        d5 = torch.cat((d5, encode_layers['e3']), dim=1)\n","        d6 = self.deconv6(d5)\n","        d6 = torch.cat((d6, encode_layers['e2']), dim=1)\n","        d7 = self.deconv7(d6)\n","        d7 = torch.cat((d7, encode_layers['e1']), dim=1)\n","        d8 = self.deconv8(d7)        \n","        fake_target = torch.tanh(d8)\n","        \n","        return fake_target"],"id":"0d615084","execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6e5ae51","executionInfo":{"status":"ok","timestamp":1636056606018,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self, category_num, img_dim=2, disc_dim=64):\n","        super(Discriminator, self).__init__()\n","        self.conv1 = conv2d(img_dim, disc_dim, bn=False)\n","        self.conv2 = conv2d(disc_dim, disc_dim*2)\n","        self.conv3 = conv2d(disc_dim*2, disc_dim*4)\n","        self.conv4 = conv2d(disc_dim*4, disc_dim*8)\n","        self.fc1 = fc(disc_dim*8*8*8, 1)\n","        self.fc2 = fc(disc_dim*8*8*8, category_num)\n","        \n","    def forward(self, images):\n","        batch_size = images.shape[0]\n","        h1 = self.conv1(images)\n","        h2 = self.conv2(h1)\n","        h3 = self.conv3(h2)\n","        h4 = self.conv4(h3)\n","        \n","        tf_loss_logit = self.fc1(h4.reshape(batch_size, -1))\n","        tf_loss = torch.sigmoid(tf_loss_logit)\n","        cat_loss = self.fc2(h4.reshape(batch_size, -1))\n","        \n","        return tf_loss, tf_loss_logit, cat_loss"],"id":"f6e5ae51","execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6898075"},"source":["# Train\n","- model Trainer"],"id":"e6898075"},{"cell_type":"code","metadata":{"id":"1e56b2ca","executionInfo":{"status":"ok","timestamp":1636056606018,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["import os, glob, time, datetime\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","from torchvision.utils import save_image"],"id":"1e56b2ca","execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"1e969dc1","executionInfo":{"status":"ok","timestamp":1636056606495,"user_tz":-540,"elapsed":479,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["class Trainer:\n","    \n","    def __init__(self, GPU, data_dir, fixed_dir, fonts_num, batch_size, img_size):\n","        self.GPU = GPU\n","        self.data_dir = data_dir\n","        self.fixed_dir = fixed_dir\n","        self.fonts_num = fonts_num\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        \n","        self.embeddings = torch.load(os.path.join(fixed_dir, 'EMBEDDINGS.pkl'))\n","        self.embedding_num = self.embeddings.shape[0]\n","        self.embedding_dim = self.embeddings.shape[3]\n","        \n","        self.fixed_source = torch.load(os.path.join(fixed_dir, 'fixed_source.pkl'))\n","        self.fixed_target = torch.load(os.path.join(fixed_dir, 'fixed_target.pkl'))\n","        self.fixed_label = torch.load(os.path.join(fixed_dir, 'fixed_label.pkl'))\n","        \n","        self.data_provider = TrainDataProvider(self.data_dir)\n","        self.total_batches = self.data_provider.compute_total_batch_num(self.batch_size)\n","        print(\"total batches:\", self.total_batches)\n","\n","\n","    def train(self, max_epoch, schedule, save_path, to_model_path, lr=0.001, \\\n","              log_step=100, sample_step=350, fine_tune=False, flip_labels=False, \\\n","              restore=None, from_model_path=False, with_charid=False, \\\n","              freeze_encoder=False, save_nrow=8, model_save_step=None, resize_fix=90):\n","\n","        # Fine Tuning coefficient\n","        if not fine_tune:\n","            L1_penalty, Lconst_penalty = 100, 15\n","        else:\n","            L1_penalty, Lconst_penalty = 500, 1000\n","\n","        # Get Models\n","        En = Encoder()\n","        De = Decoder()\n","        D = Discriminator(category_num=self.fonts_num)\n","        if self.GPU:\n","            En.cuda()\n","            De.cuda()\n","            D.cuda()\n","\n","        # Use pre-trained Model\n","        # restore에 [encoder_path, decoder_path, discriminator_path] 형태로 인자 넣기\n","        if restore:\n","            encoder_path, decoder_path, discriminator_path = restore\n","            prev_epoch = int(encoder_path.split('-')[0])\n","            En.load_state_dict(torch.load(os.path.join(from_model_path, encoder_path)))\n","            De.load_state_dict(torch.load(os.path.join(from_model_path, decoder_path)))\n","            D.load_state_dict(torch.load(os.path.join(from_model_path, discriminator_path)))\n","            print(\"%d epoch trained model has restored\" % prev_epoch)\n","        else:\n","            prev_epoch = 0\n","            print(\"New model training start\")\n","\n","\n","        # L1 loss, binary real/fake loss, category loss, constant loss\n","        if self.GPU:\n","            l1_criterion = nn.L1Loss(size_average=True).cuda()\n","            bce_criterion = nn.BCEWithLogitsLoss(size_average=True).cuda()\n","            mse_criterion = nn.MSELoss(size_average=True).cuda()\n","        else:\n","            l1_criterion = nn.L1Loss(size_average=True)\n","            bce_criterion = nn.BCEWithLogitsLoss(size_average=True)\n","            mse_criterion = nn.MSELoss(size_average=True)\n","\n","\n","        # optimizer\n","        if freeze_encoder:\n","            G_parameters = list(De.parameters())\n","        else:\n","            G_parameters = list(En.parameters()) + list(De.parameters())\n","        g_optimizer = torch.optim.Adam(G_parameters, betas=(0.5, 0.999))\n","        d_optimizer = torch.optim.Adam(D.parameters(), betas=(0.5, 0.999))\n","\n","        # losses lists\n","        l1_losses, const_losses, category_losses, d_losses, g_losses = list(), list(), list(), list(), list()\n","\n","        # training\n","        count = 0\n","        for epoch in range(max_epoch):\n","            if (epoch + 1) % schedule == 0:\n","                updated_lr = max(lr/2, 0.0002)\n","                for param_group in d_optimizer.param_groups:\n","                    param_group['lr'] = updated_lr\n","                for param_group in g_optimizer.param_groups:\n","                    param_group['lr'] = updated_lr\n","                if lr !=  updated_lr:\n","                    print(\"decay learning rate from %.5f to %.5f\" % (lr, updated_lr))\n","                lr = updated_lr\n","\n","            train_batch_iter = self.data_provider.get_train_iter(self.batch_size, \\\n","                                                            with_charid=with_charid)   \n","            for i, batch in enumerate(train_batch_iter):\n","                if with_charid:\n","                    font_ids, char_ids, batch_images = batch\n","                else:\n","                    font_ids, batch_images = batch\n","                embedding_ids = font_ids\n","                if self.GPU:\n","                    batch_images = batch_images.cuda()\n","                if flip_labels:\n","                    np.random.shuffle(embedding_ids)\n","\n","                # target / source images\n","                real_target = batch_images[:, 0, :, :]\n","                real_target = real_target.view([self.batch_size, 1, self.img_size, self.img_size])\n","                real_source = batch_images[:, 1, :, :]\n","                real_source = real_source.view([self.batch_size, 1, self.img_size, self.img_size])\n","                \n","                # centering\n","                for idx, (image_S, image_T) in enumerate(zip(real_source, real_target)):\n","                    image_S = image_S.cpu().detach().numpy().reshape(self.img_size, self.img_size)\n","                    image_S = centering_image(image_S, resize_fix=90)\n","                    real_source[idx] = torch.tensor(image_S).view([1, self.img_size, self.img_size])\n","                    image_T = image_T.cpu().detach().numpy().reshape(self.img_size, self.img_size)\n","                    image_T = centering_image(image_T, resize_fix=resize_fix)\n","                    real_target[idx] = torch.tensor(image_T).view([1, self.img_size, self.img_size])\n","\n","                # generate fake image form source image\n","                fake_target, encoded_source, _ = Generator(real_source, En, De, \\\n","                                                           self.embeddings, embedding_ids, \\\n","                                                           GPU=self.GPU, encode_layers=True)\n","\n","                real_TS = torch.cat([real_source, real_target], dim=1)\n","                fake_TS = torch.cat([real_source, fake_target], dim=1)\n","\n","                # Scoring with Discriminator\n","                real_score, real_score_logit, real_cat_logit = D(real_TS)\n","                fake_score, fake_score_logit, fake_cat_logit = D(fake_TS)\n","\n","                # Get encoded fake image to calculate constant loss\n","                encoded_fake = En(fake_target)[0]\n","                const_loss = Lconst_penalty * mse_criterion(encoded_source, encoded_fake)\n","\n","                # category loss\n","                real_category = torch.from_numpy(np.eye(self.fonts_num)[embedding_ids]).float()\n","                if self.GPU:\n","                    real_category = real_category.cuda()\n","                real_category_loss = bce_criterion(real_cat_logit, real_category)\n","                fake_category_loss = bce_criterion(fake_cat_logit, real_category)\n","                category_loss = 0.5 * (real_category_loss + fake_category_loss)\n","\n","                # labels\n","                if self.GPU:\n","                    one_labels = torch.ones([self.batch_size, 1]).cuda()\n","                    zero_labels = torch.zeros([self.batch_size, 1]).cuda()\n","                else:\n","                    one_labels = torch.ones([self.batch_size, 1])\n","                    zero_labels = torch.zeros([self.batch_size, 1])\n","\n","                # binary loss - T/F\n","                real_binary_loss = bce_criterion(real_score_logit, one_labels)\n","                fake_binary_loss = bce_criterion(fake_score_logit, zero_labels)\n","                binary_loss = real_binary_loss + fake_binary_loss\n","\n","                # L1 loss between real and fake images\n","                l1_loss = L1_penalty * l1_criterion(real_target, fake_target)\n","\n","                # cheat loss for generator to fool discriminator\n","                cheat_loss = bce_criterion(fake_score_logit, one_labels)\n","\n","                # g_loss, d_loss\n","                g_loss = cheat_loss + l1_loss + fake_category_loss + const_loss\n","                d_loss = binary_loss + category_loss\n","\n","                # train Discriminator\n","                D.zero_grad()\n","                d_loss.backward(retain_graph=True)\n","                d_optimizer.step()\n","\n","                # train Generator\n","                En.zero_grad()\n","                De.zero_grad()\n","                g_loss.backward(retain_graph=True)\n","                g_optimizer.step()            \n","\n","                # loss data\n","                l1_losses.append(int(l1_loss.data))\n","                const_losses.append(int(const_loss.data))\n","                category_losses.append(int(category_loss.data))\n","                d_losses.append(int(d_loss.data))\n","                g_losses.append(int(g_loss.data))\n","\n","                # logging\n","                if (i+1) % log_step == 0:\n","                    time_ = time.time()\n","                    time_stamp = datetime.datetime.fromtimestamp(time_).strftime('%H:%M:%S')\n","                    log_format = 'Epoch [%d/%d], step [%d/%d], l1_loss: %.4f, d_loss: %.4f, g_loss: %.4f' % \\\n","                                 (int(prev_epoch)+epoch+1, int(prev_epoch)+max_epoch, \\\n","                                  i+1, self.total_batches, l1_loss.item(), d_loss.item(), g_loss.item())\n","                    print(time_stamp, log_format)\n","\n","                # save image\n","                if (i+1) % sample_step == 0:\n","                    fixed_fake_images = Generator(self.fixed_source, En, De, \\\n","                                                  self.embeddings, self.fixed_label, GPU=self.GPU)[0]\n","                    save_image(denorm_image(fixed_fake_images.data), \\\n","                               os.path.join(save_path, 'fake_samples-%d-%d.png' % \\\n","                                            (int(prev_epoch)+epoch+1, i+1)), \\\n","                               nrow=save_nrow, pad_value=255)\n","\n","            if not model_save_step:\n","                model_save_step = 5\n","            if (epoch+1) % model_save_step == 0:\n","                now = datetime.datetime.now()\n","                now_date = now.strftime(\"%m%d\")\n","                now_time = now.strftime('%H:%M')\n","                torch.save(En.state_dict(), os.path.join(to_model_path, \\\n","                                                         '%d-%s-%s-Encoder.pkl' % \\\n","                                                         (int(prev_epoch)+epoch+1, \\\n","                                                          now_date, now_time)))\n","                torch.save(De.state_dict(), os.path.join(to_model_path, \\\n","                                                         '%d-%s-%s-Decoder.pkl' % \\\n","                                                         (int(prev_epoch)+epoch+1, \\\n","                                                          now_date, now_time)))\n","                torch.save(D.state_dict(), os.path.join(to_model_path, \\\n","                                                        '%d-%s-%s-Discriminator.pkl' % \\\n","                                                        (int(prev_epoch)+epoch+1, \\\n","                                                         now_date, now_time)))\n","\n","        # save model\n","        total_epoch = int(prev_epoch) + int(max_epoch)\n","        end = datetime.datetime.now()\n","        end_date = end.strftime(\"%m%d\")\n","        end_time = end.strftime('%H:%M')\n","        torch.save(En.state_dict(), os.path.join(to_model_path, \\\n","                                                 '%d-%s-%s-Encoder.pkl' % \\\n","                                                 (total_epoch, end_date, end_time)))\n","        torch.save(De.state_dict(), os.path.join(to_model_path, \\\n","                                                 '%d-%s-%s-Decoder.pkl' % \\\n","                                                 (total_epoch, end_date, end_time)))\n","        torch.save(D.state_dict(), os.path.join(to_model_path, \\\n","                                                '%d-%s-%s-Discriminator.pkl' % \\\n","                                                (total_epoch, end_date, end_time)))\n","        losses = [l1_losses, const_losses, category_losses, d_losses, g_losses]\n","        torch.save(losses, os.path.join(to_model_path, '%d-losses.pkl' % total_epoch))\n","\n","        return l1_losses, const_losses, category_losses, d_losses, g_losses"],"id":"1e969dc1","execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"523cce6c"},"source":["# Main\n","\n","- preprocessing :\n","        - pre training      : .ttf -> .png -> .pki\n","        - transfer learning : .pdf -> .png -> .pki\n","- pretraining   : Trainer 사용\n","- training rusult post-processing\n","\n","src : 고딕체<br>\n","dst : 왜곡된. 학습하는 폰트"],"id":"523cce6c"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fmZYrILN-_q","executionInfo":{"status":"ok","timestamp":1636056628549,"user_tz":-540,"elapsed":22056,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}},"outputId":"383d39e4-ad8a-433f-8587-83db0dbfeed4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"id":"2fmZYrILN-_q","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMSAkbO0PcqL","executionInfo":{"status":"ok","timestamp":1636056633757,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}},"outputId":"4e11a536-347c-403a-ca99-b3ffdf19933c"},"source":["cd /content/drive/My Drive/capstone_design_3_2"],"id":"YMSAkbO0PcqL","execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/capstone_design_3_2\n"]}]},{"cell_type":"code","metadata":{"id":"cfe95dbc","executionInfo":{"status":"ok","timestamp":1636056701466,"user_tz":-540,"elapsed":64624,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["# 손글씨 template 이미지 입력\n","from PIL import Image\n","\n","template = Image.open('210_template-1.png')\n","template = template.convert('L')\n","\n","if template.size != (1654, 2339):\n","    teplate = template.resize((1654, 2339))\n","    \n","line = [2,2,2,3,2,2,3,2,3,2,2,3,2,2,2]\n","up = 113\n","for i in range(14):\n","    left = 57\n","    if i in [4,7,9,11,13]:\n","        up += 1\n","    for j in range(15):\n","        croppedImage = template.crop((left, up, left+100, up+100))\n","        file_name = \"./handwriting/\" + str(i*15+j+1) + \".png\"\n","        croppedImage.save(file_name)\n","        left = left + 100 + line[j]\n","    up += 157"],"id":"cfe95dbc","execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c760f79","executionInfo":{"status":"ok","timestamp":1636056436604,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["tmpl_target = open(\"template_target.txt\",'r', encoding = 'utf-8')\n","tmpl_target.close()"],"id":"3c760f79","execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48f2e818","executionInfo":{"status":"ok","timestamp":1636056745930,"user_tz":-540,"elapsed":1545,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}},"outputId":"a5abb141-c318-4bd8-d574-a354a72809db"},"source":["label_file = open(\"2350-common-hangul.txt\", 'r', encoding = 'utf-8')\n","ch = label_file.readline().replace('\\n', '')\n","line = 0\n","while ch:\n","    line +=1\n","    ch = label_file.readline().replace('\\n', '')\n","print (line)"],"id":"48f2e818","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["2350\n"]}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"d2eaf9d6","executionInfo":{"status":"ok","timestamp":1636058286133,"user_tz":-540,"elapsed":87036,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}}},"source":["src_font = ImageFont.truetype(SRC_PATH + \"source_font.ttf\",100)\n","canvas_size = 128\n","for index in range(56):\n","    ttf_index = str(index+1).zfill(2)\n","    ttf_name = ttf_index+\".ttf\"\n","    dst_font = ImageFont.truetype(TRG_PATH + ttf_name ,100)\n","    \n","    label_file = open(\"2350-common-hangul.txt\", 'r', encoding = 'utf-8')\n","    ch =label_file.readline().replace('\\n', '')\n","    line = 1\n","    while ch:\n","        made_img = draw_example(ch, src_font, dst_font, canvas_size)\n","        new_img_name = OUTPUT_PATH+ttf_index+\"_\"+str(line)+\".png\"\n","        made_img.save(new_img_name,format='PNG')\n","        #다음 줄 읽기\n","        ch = label_file.readline().replace('\\n', '')\n","        line += 1\n","    label_file.close()"],"id":"d2eaf9d6","execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"24119efe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636058411854,"user_tz":-540,"elapsed":125721,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}},"outputId":"b28e5a01-2a99-4b72-89ad-c6bfd97696e3"},"source":["train_path = OUTPUT_PATH + 'train.obj'\n","val_path = OUTPUT_PATH + 'val.obj'\n","pickle_examples(OUTPUT_PATH,train_path,val_path)"],"id":"24119efe","execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["all data num: 131600\n","10000 imgs saved in train.obj\n","20000 imgs saved in train.obj\n","30000 imgs saved in train.obj\n","10000 imgs saved in val.obj\n","40000 imgs saved in train.obj\n","50000 imgs saved in train.obj\n","60000 imgs saved in train.obj\n","70000 imgs saved in train.obj\n","20000 imgs saved in val.obj\n","80000 imgs saved in train.obj\n","90000 imgs saved in train.obj\n","100000 imgs saved in train.obj\n","26357 imgs saved in val.obj, end\n","105243 imgs saved in train.obj, end\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"id":"cf6261a2","executionInfo":{"status":"error","timestamp":1636058535345,"user_tz":-540,"elapsed":1706,"user":{"displayName":"‍정세연[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852209650884092588"}},"outputId":"6d2b4aa4-4bf5-4148-af87-04d4529f7dd2"},"source":["sample_size = 16 #tensor ver (original code) value & 위에 셀 참고\n","img_size = 128\n","data_dir = OUTPUT_PATH\n","save_dir = './dataset_pki/'\n","save_fixed_sample(sample_size, img_size, data_dir, save_dir)"],"id":"cf6261a2","execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["unpickled total 105243 examples\n","train examples -> 105243\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-3af29c3cbdeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./dataset_pki/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msave_fixed_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-40-cd22cef2ef3a>\u001b[0m in \u001b[0;36msave_fixed_sample\u001b[0;34m(sample_size, img_size, data_dir, save_dir, val, verbose, with_charid, resize_fix)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_batch_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_val_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_charid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_charid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_charid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mfont_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-e47b336b1654>\u001b[0m in \u001b[0;36mbatch_iter\u001b[0;34m(with_charid)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_charid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcharid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-e47b336b1654>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_charid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcharid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"cell_type":"code","metadata":{"id":"bEY0fX9fRFKc"},"source":["#GPU check\n"],"id":"bEY0fX9fRFKc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2191cad"},"source":["GPU = # GPU 대여 확인\n","data_dir = #pickle data가 저장된 곳\n","fixed_dir = \"./pre-result/\"\n","fonts_num = 56\n","batch_size = 16 #tensor ver original code value\n","img_size = 128\n","\n","HandwritingFontML = Trainer(GPU, data_dir, fixed_dir, fonts_num, batch_size, img_size)"],"id":"c2191cad","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"031ea9bb"},"source":["def interpolation(data_provider, grids, fixed_char_ids, interpolated_font_ids, embeddings, \\\n","                  En, De, batch_size, img_size=128, save_nrow=6, save_path=False, GPU=True):\n","    \n","    train_batch_iter = data_provider.get_train_iter(batch_size, with_charid=True)\n","    \n","    for grid_idx, grid in enumerate(grids):\n","        train_batch_iter = data_provider.get_train_iter(batch_size, with_charid=True)\n","        grid_results = {from_to: {charid: None for charid in fixed_char_ids} \\\n","                        for from_to in interpolated_font_ids}\n","\n","        for i, batch in enumerate(train_batch_iter):\n","            font_ids_from, char_ids, batch_images = batch\n","            font_filter = [i[0] for i in interpolated_font_ids]\n","            font_filter_plus = font_filter + [font_filter[0]]\n","            font_ids_to = [font_filter_plus[font_filter.index(i)+1] for i in font_ids_from]\n","            batch_images = batch_images.cuda()\n","\n","            real_sources = batch_images[:, 1, :, :].view([batch_size, 1, img_size, img_size])\n","            real_targets = batch_images[:, 0, :, :].view([batch_size, 1, img_size, img_size])\n","\n","            for idx, (image_S, image_T) in enumerate(zip(real_sources, real_targets)):\n","                image_S = image_S.cpu().detach().numpy().reshape(img_size, img_size)\n","                image_S = centering_image(image_S, resize_fix=100)\n","                real_sources[idx] = torch.tensor(image_S).view([1, img_size, img_size])\n","                image_T = image_T.cpu().detach().numpy().reshape(img_size, img_size)\n","                image_T = centering_image(image_T, resize_fix=100)\n","                real_targets[idx] = torch.tensor(image_T).view([1, img_size, img_size])\n","                \n","            encoded_source, encode_layers = En(real_sources)\n","\n","            interpolated_embeddings = []\n","            embedding_dim = embeddings.shape[3]\n","            for from_, to_ in zip(font_ids_from, font_ids_to):\n","                interpolated_embeddings.append((embeddings[from_] * (1 - grid) + \\\n","                                                embeddings[to_] * grid).cpu().numpy())\n","            interpolated_embeddings = torch.tensor(interpolated_embeddings).cuda()\n","            interpolated_embeddings = interpolated_embeddings.reshape(batch_size, embedding_dim, 1, 1)\n","\n","            # generate fake image with embedded source\n","            interpolated_embedded = torch.cat((encoded_source, interpolated_embeddings), 1)\n","            fake_targets = De(interpolated_embedded, encode_layers)\n","\n","            # [(0)real_S, (1)real_T, (2)fake_T]\n","            for fontid, charid, real_S, real_T, fake_T in zip(font_ids_from, char_ids, \\\n","                                                              real_sources, real_targets, \\\n","                                                              fake_targets):\n","                font_from = fontid\n","                font_to = font_filter_plus[font_filter.index(fontid)+1]\n","                from_to = (font_from, font_to)\n","                grid_results[from_to][charid] = [real_S, real_T, fake_T]\n","\n","        if save_path:\n","            for from_to in grid_results.keys():\n","                image = [grid_results[from_to][charid][2].cpu().detach().numpy() for \\\n","                         charid in fixed_char_ids]\n","                image = torch.tensor(np.array(image))\n","\n","                # path\n","                font_from = str(from_to[0])\n","                font_to = str(from_to[1])\n","                grid_idx = str(grid_idx)\n","                if len(font_from) == 1:\n","                    font_from = '0' + font_from\n","                if len(font_to) == 1:\n","                    font_to = '0' + font_to\n","                if len(grid_idx) == 1:\n","                    grid_idx = '0' + grid_idx\n","                idx = str(interpolated_font_ids.index(from_to))\n","                if len(idx) == 1:\n","                    idx = '0' + idx\n","                file_path = '%s_from_%s_to_%s_grid_%s.png' % (idx, font_from, font_to, grid_idx)\n","\n","                # save\n","                save_image(denorm_image(image.data), \\\n","                           os.path.join(save_path, file_path), \\\n","                           nrow=save_nrow, pad_value=255)\n","    \n","    return grid_results"],"id":"031ea9bb","execution_count":null,"outputs":[]}]}